---
title: "Lake Water Quality Analysis"
author: "John Kemper"
date: "9/25/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---



```{r setup, include=FALSE}
library(tidyverse) # Tidy packages
library(sf) #Spatial package that can read and create shapefiles 
library(mapview) #Interactive maps
library(LAGOSNE) #Lots and lots of clean lake data
library(USAboundaries) #USA states and counties
library(lubridate) #For dealing with date and time
library(ggplot2) ##ggplot
library(ggthemes) ##themes in ggplot

```


# LAGOS Analysis


## Loading in data


### First download and then specifically grab the locus (or site lat longs)
```{r data-read}
#Lagos download script
lagosne_get(dest_folder = LAGOSNE:::lagos_path())

#Load in lagos
lagos <- lagosne_load()


#Grab the lake centroid info
lake_centers <- lagos$locus

# Make an sf object 
spatial_lakes <- st_as_sf(lake_centers,coords=c('nhd_long','nhd_lat'),
                          crs=4326)

#Grab the water quality data
nutr <- lagos$epi_nutr

#Look at column names
#names(nutr)
```

### Subset columns nutr to only keep key info that we want


```{r}
clarity_only <- nutr %>%
  select(lagoslakeid,sampledate,chla,doc,secchi) %>%
  mutate(sampledate = as.character(sampledate) %>% ymd(.))

head(clarity_only)

```


### Keep sites with at least 200 observations 

```{r}


#Look at the number of rows of dataset
nrow(clarity_only)

chla_secchi <- clarity_only %>%
  filter(!is.na(chla),
         !is.na(secchi))
head(chla_secchi)
# How many observatiosn did we lose? - We lost 89715 observations
nrow(clarity_only) - nrow(chla_secchi)


# Keep only the lakes with at least 200 observations of secchi and chla
chla_secchi_200 <- chla_secchi %>%
  group_by(lagoslakeid) %>%
  mutate(count = n()) %>%
  filter(count > 200) 

# chla_secchi_200
```


### Join water quality data to spatial data

```{r}
spatial_200 <- inner_join(spatial_lakes,chla_secchi_200 %>%
                            distinct(lagoslakeid,.keep_all=T),
                          by='lagoslakeid')

mapview(spatial_200)

```

### Mean Chl_a map

```{r}
### Take the mean chl_a and secchi by lake

mean_values_200 <- chla_secchi_200 %>% 
  group_by(lagoslakeid) %>%
  summarise(mean_chla = mean(chla, na.rm = TRUE),
            mean_secchi = mean(secchi), na.rm = TRUE) %>%
  filter(!is.na(mean_chla),
         !is.na(mean_secchi)) %>%
  mutate(log10_mean_chla = log10(mean_chla))



#Join datasets
mean_spatial <- inner_join(spatial_lakes,mean_values_200,
                          by='lagoslakeid') 

#Make a map
mapview(mean_spatial,zcol='log10_mean_chla')
```


# Class work

## 1) What is the correlation between Secchi Disk Depth and Chlorophyll a for
sites with at least 200 observations?

- Here, I just want a plot of chla vs secchi for all sites 

```{r}

###plot chla vs secchi
mean_values_200 %>%
  ggplot(., aes( x= mean_secchi, y = log10_mean_chla)) +
  geom_point(size = 3, shape = 17, color = "forestgreen") +
  theme_few() +
  theme(text = element_text(size = 16, color = "black")) +
  xlab("Mean Secchi Disk Depth (m)") +
  ylab("Log Mean Chlorophyll Conc. (mg/L)")


```


## Why might this be the case? 

```{r}
### The deeper the depth the less sunlight, so the less the chlorophyll concentration
```



## 2) What states have the most data? 

### 2a) First you will need to make a lagos spatial dataset that has the total 
number of counts per site.

```{r}
###Count number of  measurements per lake
chla_secchi_obs <- chla_secchi %>%
  mutate(count = n())

```


### 2b) Second, you will need to join this point dataset to the us_boundaries 
data. 

```{r}

###join the data on chla and secchi observations to spatial lake dataset
ch_sech_spatial <- inner_join(spatial_lakes, chla_secchi_obs %>%
                            distinct(lagoslakeid,.keep_all=T),
                          by='lagoslakeid') %>% st_transform(2163)

states <- us_states() %>%
  st_transform(2163)

###join the spatial observation data set created above to the state data set in order to associate observation 
###count with a state
state_obs <- st_join(ch_sech_spatial, states)

```


### 2c) Then you will want to group by state and sum all the observations in that
state and arrange that data from most to least toatl observations per state. 

```{r}
View(state_obs)

###Group observations by state and arrange the list from most to least observations
total_obs <- state_obs %>%
  group_by(name) %>%
  summarise(n = n()) %>%
  arrange(desc(n)) %>%
  select("name", "n")

head(total_obs)

####Minnesota has the most observations
```
?desc
##3 Is there a spatial pattern in Secchi disk depth for lakes with at least 200 
observations?

```{r}

names(mean_spatial)

###map the mean secchi disk depth for lakes with at least 200 observations
mapview(mean_spatial, zcol = "mean_secchi")

####Lakes in New England appear to have a larger (i.e. deeper) mean Secchi disk depth than lakes in the Midwest 



```


